{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea69652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import openai\n",
    "import functools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e439c9",
   "metadata": {},
   "source": [
    "# Process the Squad JSON to extract what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4290fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_json('data/squad2.json')['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696cbaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paragraphs = [paragraph['context'] for ent in d for paragraph in ent['paragraphs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok. list comprehension is still possible but it gets a little obnoxious.\n",
    "all_qa = []\n",
    "paragraph_id = 0\n",
    "for ent in d:\n",
    "    for paragraph in ent['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            if len(qa['answers']) > 0 and qa['is_impossible'] == False:\n",
    "                all_qa.append((paragraph_id, qa['question'], qa['answers'][0]['text']))\n",
    "        paragraph_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9bf620",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fbf354",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paragraphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88193838",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qa[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/paragraphs_and_qa.pickle','wb')\n",
    "pickle.dump(all_paragraphs, f)\n",
    "pickle.dump(all_qa, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e71a64",
   "metadata": {},
   "source": [
    "# Baseline OpenAI QA. Knowing exactly the paragraphs to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea43f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/paragraphs_and_qa.pickle','rb')\n",
    "all_paragraphs = pickle.load(f)\n",
    "all_qa = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79825e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(max_retries=5,timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5194aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "733e2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answerer(client, question, context):\n",
    "    global qa_cache\n",
    "    key = context + question\n",
    "    if key in qa_cache:\n",
    "        return qa_cache[key]\n",
    "    system_prompt = \"You are an assistant for question-answering tasks. Use the provided pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Provide just the answer in as few words as possible. Do not use complete sentences.\"\n",
    "    user_prompt = f\"Question: {question} \\nContext: {context} \\nAnswer:\"\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    response = response.choices[0].message.content\n",
    "    qa_cache[key] = response\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b10782c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
      "When did Beyonce start becoming popular?\n",
      "in the late 1990s\n"
     ]
    }
   ],
   "source": [
    "para_id, question, answer = all_qa[0]\n",
    "print(all_paragraphs[para_id])\n",
    "print(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e90d944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late 1990s\n"
     ]
    }
   ],
   "source": [
    "response = question_answerer(client, question, all_paragraphs[para_id])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc803d6f",
   "metadata": {},
   "source": [
    "## Coming with a simple comparison evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81bd15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_same_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7781c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same(client, question, a1, a2):\n",
    "    global is_same_cache\n",
    "    key = question + ' '  +a1 + ' ' + a2\n",
    "    if key in is_same_cache:\n",
    "        return is_same_cache[key]\n",
    "\n",
    "    system_prompt = \"You are an assistant for scoring answers. Two answers to a hypothetical question are provided. Say 'Yes' if both answers have the same meaning, and 'No' otherwise.\"\n",
    "    user_prompt = f\"Question: {question} \\Answer 1: {a1} \\nAnswer 2: {a2}\"\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.0\n",
    "    )\n",
    "    response = response.choices[0].message.content == 'Yes'\n",
    "    is_same_cache[key] = response\n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85d216b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the late 1990s'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59befdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_same(client, question, answer, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05b59e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_same(client, question, answer, \"Late 1980s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4815f9a",
   "metadata": {},
   "source": [
    "# Evaluate RAG\n",
    "80k questions at about 1k tokens per question == ~ 0.0010 * 80000 or about $80. That is a bit pricy for a quick test. We will subsample to ~ 10% questions.\n",
    "Note that this part is really entirely irrelevant and not that useful. But its a fun thing to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92563b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sub_qa = all_qa[0:len(all_qa):10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17884682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81c09b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_work(client, question, true_answer, context):\n",
    "    response = question_answerer(client, question, context)\n",
    "    evaluation = is_same(client, question, true_answer, response)\n",
    "    return true_answer, response, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "responses = []\n",
    "evaluations = []\n",
    "futures = []\n",
    "ctr = 0\n",
    "for ent in sub_qa:\n",
    "    para_id, question, true_answer = ent\n",
    "    try:\n",
    "        true_answer, response, evaluation = do_work(client, question, true_answer, all_paragraphs[para_id])\n",
    "    except openai.RateLimitError:\n",
    "        time.sleep(60)\n",
    "        true_answer, response, evaluation = do_work(client, question, true_answer, all_paragraphs[para_id])\n",
    "    ctr += 1\n",
    "    print(f\"Correct Answer: {true_answer}, Response: {response}, Eval: {evaluation}. {ctr}/{total_futures}\")\n",
    "    responses.append(response)\n",
    "    evaluations.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afbb99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9bca57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['context'] = [all_paragraphs[i[0]] for i in sub_qa]\n",
    "df['question'] = [i[1] for i in sub_qa]\n",
    "df['answer'] = [i[2] for i in sub_qa]\n",
    "df['response'] = responses\n",
    "df['evaluations'] = evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9bf8f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>response</th>\n",
       "      <th>evaluations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>Late 1990s</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What was the first album Beyoncé released as a...</td>\n",
       "      <td>Dangerously in Love</td>\n",
       "      <td>Dangerously in Love</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Following the disbandment of Destiny's Child i...</td>\n",
       "      <td>Which album was darker in tone from her previo...</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé (2013)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A self-described \"modern-day feminist\", Beyonc...</td>\n",
       "      <td>In which decade did the Recording Industry Ass...</td>\n",
       "      <td>2000s</td>\n",
       "      <td>2000s</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyoncé Giselle Knowles was born in Houston, T...</td>\n",
       "      <td>Where did Beyonce get her name from?</td>\n",
       "      <td>her mother's maiden name</td>\n",
       "      <td>Her mother's maiden name.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8678</th>\n",
       "      <td>The Bagmati River which flows through Kathmand...</td>\n",
       "      <td>In a Hindu funeral, who is typically the main ...</td>\n",
       "      <td>first son</td>\n",
       "      <td>The first son.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8679</th>\n",
       "      <td>Kirant Mundhum is one of the indigenous animis...</td>\n",
       "      <td>What is another name for ancestor worship?</td>\n",
       "      <td>worship of Ajima</td>\n",
       "      <td>Ajima worship</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8680</th>\n",
       "      <td>Institute of Medicine, the central college of ...</td>\n",
       "      <td>What institution of tertiary education is know...</td>\n",
       "      <td>National Academy of Medical Sciences</td>\n",
       "      <td>National Academy of Medical Sciences</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681</th>\n",
       "      <td>The total length of roads in Nepal is recorded...</td>\n",
       "      <td>If one wished to travel north out of Kathmandu...</td>\n",
       "      <td>Araniko</td>\n",
       "      <td>Araniko Highway</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8682</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>Kathmandu Metropolitan City</td>\n",
       "      <td>Kathmandu Metropolitan City</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8683 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context   \n",
       "0     Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  \\\n",
       "1     Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "2     Following the disbandment of Destiny's Child i...   \n",
       "3     A self-described \"modern-day feminist\", Beyonc...   \n",
       "4     Beyoncé Giselle Knowles was born in Houston, T...   \n",
       "...                                                 ...   \n",
       "8678  The Bagmati River which flows through Kathmand...   \n",
       "8679  Kirant Mundhum is one of the indigenous animis...   \n",
       "8680  Institute of Medicine, the central college of ...   \n",
       "8681  The total length of roads in Nepal is recorded...   \n",
       "8682  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                               question   \n",
       "0              When did Beyonce start becoming popular?  \\\n",
       "1     What was the first album Beyoncé released as a...   \n",
       "2     Which album was darker in tone from her previo...   \n",
       "3     In which decade did the Recording Industry Ass...   \n",
       "4                  Where did Beyonce get her name from?   \n",
       "...                                                 ...   \n",
       "8678  In a Hindu funeral, who is typically the main ...   \n",
       "8679         What is another name for ancestor worship?   \n",
       "8680  What institution of tertiary education is know...   \n",
       "8681  If one wished to travel north out of Kathmandu...   \n",
       "8682                      What is KMC an initialism of?   \n",
       "\n",
       "                                    answer   \n",
       "0                        in the late 1990s  \\\n",
       "1                      Dangerously in Love   \n",
       "2                                  Beyoncé   \n",
       "3                                    2000s   \n",
       "4                 her mother's maiden name   \n",
       "...                                    ...   \n",
       "8678                             first son   \n",
       "8679                      worship of Ajima   \n",
       "8680  National Academy of Medical Sciences   \n",
       "8681                               Araniko   \n",
       "8682           Kathmandu Metropolitan City   \n",
       "\n",
       "                                  response  evaluations  \n",
       "0                               Late 1990s         True  \n",
       "1                      Dangerously in Love         True  \n",
       "2                           Beyoncé (2013)         True  \n",
       "3                                    2000s         True  \n",
       "4                Her mother's maiden name.         True  \n",
       "...                                    ...          ...  \n",
       "8678                        The first son.         True  \n",
       "8679                         Ajima worship         True  \n",
       "8680  National Academy of Medical Sciences         True  \n",
       "8681                       Araniko Highway         True  \n",
       "8682           Kathmandu Metropolitan City         True  \n",
       "\n",
       "[8683 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6af7534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data/qa_result_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a66db",
   "metadata": {},
   "source": [
    "# OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c767a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_openai_embeddings(client, textlist):\n",
    "    ret = []\n",
    "    ctr = 0\n",
    "    total = len(textlist)\n",
    "    for ent in textlist:\n",
    "        ctr += 1\n",
    "        try:\n",
    "            res = client.embeddings.create(input=ent, model='text-embedding-ada-002', encoding_format='float')\n",
    "        except openai.RateLimitError:\n",
    "            time.sleep(60)\n",
    "            res = client.embeddings.create(input=ent, model='text-embedding-ada-002', encoding_format='float')\n",
    "        ret.append(res.data[0].embedding)\n",
    "        print(f\"{ctr}/{total}\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb08cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_embeddings = generate_openai_embeddings(client, all_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d63be342",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_embeddings_arr = np.array(par_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52c45d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/openai_paragraphs_embeddings.npy', par_embeddings_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "qn_embeddings = generate_openai_embeddings(client, [q[1] for q in all_qa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b535be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qn_embeddings_arr = np.array(qn_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1eb6b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/openai_qn_embeddings.npy', qn_embeddings_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5366e2",
   "metadata": {},
   "source": [
    "# Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f108dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9b6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_embeddings_arr = np.load('data/openai_paragraphs_embeddings.npy')\n",
    "qn_embeddings_arr = np.load('data/openai_qn_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8135e067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;ball_tree&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;ball_tree&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', n_neighbors=10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=10, algorithm='ball_tree')\n",
    "nbrs.fit(par_embeddings_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57771beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = nbrs.kneighbors(qn_embeddings_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93b74bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.53342373, 0.54183945, 0.5480534 , ..., 0.55267631, 0.55477935,\n",
       "         0.55652812],\n",
       "        [0.51625546, 0.56791918, 0.57577417, ..., 0.60289394, 0.60317292,\n",
       "         0.60357273],\n",
       "        [0.47841394, 0.49049756, 0.51447069, ..., 0.54367424, 0.5441335 ,\n",
       "         0.54597068],\n",
       "        ...,\n",
       "        [0.57681319, 0.59904399, 0.59999977, ..., 0.6253042 , 0.62548659,\n",
       "         0.62892828],\n",
       "        [0.49743956, 0.57099157, 0.5722643 , ..., 0.59779   , 0.60029111,\n",
       "         0.60105112],\n",
       "        [0.6205644 , 0.67376102, 0.68988245, ..., 0.70489665, 0.70647834,\n",
       "         0.70827299]]),\n",
       " array([[   23,    45,    26, ...,    50,     0,    14],\n",
       "        [    4,     5,     3, ...,    64,    42,    20],\n",
       "        [    1,    11,     8, ...,     7,    23,    36],\n",
       "        ...,\n",
       "        [18979, 18929, 18925, ..., 18966, 18972, 18934],\n",
       "        [18979, 18932, 18940, ..., 18978, 18972, 18941],\n",
       "        [18979, 18255,  3350, ...,   126, 13786, 11440]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30358371",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/openai_knn_qn_to_paragraph.npy', knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2550df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, nearest_paragraphs = knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7051167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86821, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_paragraphs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90fcdc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array([i[0] for i in all_qa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77d0c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_at = []\n",
    "p_at.append((nearest_paragraphs[:,0] == truth).sum())\n",
    "for i in range(1,10):\n",
    "    p = (nearest_paragraphs[:,i] == truth).sum()\n",
    "    p_at.append(p_at[i-1] + p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a07d8f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54566, 63738, 67928, 70421, 72127, 73358, 74400, 75232, 75857, 76395]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659028e",
   "metadata": {},
   "source": [
    "# Simpler Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0cef5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c2e4b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = [par.split(\" \") for par in all_paragraphs]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6175c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "bm25_nearest_paragraphs = []\n",
    "ctr = 0\n",
    "for qa in all_qa:\n",
    "    z = bm25.get_scores(qa[1].split(\" \"))\n",
    "    bm25_nearest_paragraphs.append(np.argsort(-z)[:10].copy())\n",
    "    ctr += 1\n",
    "    if ctr % 100 == 0:\n",
    "        print(ctr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca118e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
